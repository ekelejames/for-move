services:
  kafka-2:
    image: confluentinc/cp-server:7.6.0
    container_name: kafka-2
    ports:
      - "29094:29094"
      - "9094:9094"
    environment:
      CLUSTER_ID: 'xVwOh_nFSfq2tXYyxPXDTF'
      KAFKA_BROKER_ID: 2
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '2@0.0.0.0:29093'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,INTERNAL:SASL_PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: 'INTERNAL://0.0.0.0:9094,EXTERNAL://0.0.0.0:29094,CONTROLLER://0.0.0.0:29093'
      KAFKA_ADVERTISED_LISTENERS: 'INTERNAL://kafka-2:9094,EXTERNAL://kafka-2:29094' # i changed this to kafka from localhost
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8085
      KAFKA_LOG_DIRS: '/var/lib/kafka/data-2'
      KAFKA_AUTHORIZER_CLASS_NAME: io.confluent.kafka.security.authorizer.ConfluentServerAuthorizer
      KAFKA_CONFLUENT_AUDIT_LOG_ENABLED: true
      KAFKA_CONFLUENT_AUDIT_LOG_INCLUDE: kafka.AlterClientQuotas,kafka.AlterConfigs,kafka.AlterIsr,kafka.AlterMirrors,kafka.AlterPartitionReassignments,kafka.AlterReplicaLogDirs,kafka.AlterUserScramCredentials,kafka.CreateAcls,kafka.CreateClusterLinks,kafka.CreatePartitions,kafka.CreateTopics,kafka.DeleteAcls,kafka.DeleteClusterLinks,kafka.DeleteGroups,kafka.DeleteRecords,kafka.DeleteTopics,kafka.ElectLeaders,kafka.IncrementalAlterConfigs,kafka.InitiateShutdown,kafka.OffsetDelete,kafka.RemoveBrokers,kafka.UpdateFeatures

#      KAFKA_CONFLUENT_SECURITY_EVENT_ROUTER_CONFIG: "/config/security-event-router-config.json"

      # enabling acls
      #KAFKA_AUTHORIZER_CLASS_NAME: org.apache.kafka.metadata.authorizer.StandardAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "false"
      KAFKA_SUPER_USERS: "User:admin;User:ANONYMOUS"

      # Specify the sasl mechanisms enabled
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN #SCRAM-SHA-512

      # specifying inter broker protocol
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN #SCRAM-SHA-512

      # Security configuration for external listener
      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/jaas.conf"

      # connecting to external listener
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka-2:9094
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
      CONFLUENT_METRICS_REPORTER_SASL_MECHANISM: PLAIN
      CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONFLUENT_METRICS_REPORTER_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin-secret";'

      # Configuring debugging level
      KAFKA_LOG4J_ROOT_LOGLEVEL: 'INFO'
      KAFKA_LOG4J_LOGGERS: 'kafka=INFO,kafka.controller=INFO,kafka.log.LogCleaner=INFO,state.change.logger=INFO,kafka.producer.async.DefaultEventHandler=INFO'
      KAFKA_SASL_KERBEROS_SERVICE_NAME: kafka
    volumes:
      - ./kafka-data-2:/var/lib/kafka/data
      - ./jaas.conf:/etc/kafka/jaas.conf
      - ./security-event-router-config.json:/config/security-event-router-config.json


  # kafka-connect:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.kafka-connect
  #   container_name: kafka-connect
  #   depends_on:
  #     - kafka
  #     - schema-registry
  #   ports:
  #     - "8083:8083"
  #   environment:
  #     CONNECT_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka:29092'
  #     CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect'
  #     CONNECT_GROUP_ID: 'kafka-connect-group'
  #     CONNECT_CONFIG_STORAGE_TOPIC: 'connect-configs'
  #     CONNECT_OFFSET_STORAGE_TOPIC: 'connect-offsets'
  #     CONNECT_STATUS_STORAGE_TOPIC: 'connect-status'
  #     CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.storage.StringConverter'
  #     CONNECT_VALUE_CONVERTER: 'io.confluent.connect.json.JsonSchemaConverter'
  #     CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
  #     CONNECT_REST_PORT: 8083
  #     CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components,/kafka-plugins'
  #     CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
  #     CONNECT_LOG4J_LOGGERS: 'org.reflections=ERROR'
  #   volumes:
      # - ./plugins/kafka-plugins:/kafka-plugins
      # - ./metrics/sample-flat-schema-metric/config:/sample-flat-schema-metric-config
      # - ./scripts:/scripts
      # - ./metrics/sample-nested-schema-metric/config:/sample-nested-schema-metric-config
      # - ./mongodb-kafka-connect-mongodb-1.14.1:/usr/share/confluent-hub-components
#    entrypoint: ["sh", "/scripts/init-kafka-connect.sh"]
#    healthcheck:
#      test: ["CMD", "curl", "-f", "http://localhost:8083/"]
#      interval: 30s
#      timeout: 10s
#      retries: 5


  kafka-connect-2:
    build:
      context: .
      dockerfile: Dockerfile.kafka-connect
    container_name: kafka-connect-2
    depends_on:
      - kafka-2
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'SASL_PLAINTEXT://kafka-2:9094'
      CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect'
      CONNECT_GROUP_ID: 'kafka-connect-group'
      CONNECT_CONFIG_STORAGE_TOPIC: 'connect-configs'
      CONNECT_OFFSET_STORAGE_TOPIC: 'connect-offsets'
      CONNECT_STATUS_STORAGE_TOPIC: 'connect-status'
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.storage.StringConverter'
      CONNECT_VALUE_CONVERTER: 'io.confluent.connect.json.JsonSchemaConverter'
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
      CONNECT_REST_PORT: 8083
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components,/kafka-plugins'
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CONNECT_LOG4J_LOGGERS: 'org.reflections=ERROR'

      CONNECT_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin-secret";'
      CONNECT_SASL_MECHANISM: PLAIN

      CONNECT_PRODUCER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_PRODUCER_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin-secret";'
      CONNECT_PRODUCER_SASL_MECHANISM: PLAIN

      CONNECT_CONSUMER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_CONSUMER_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin-secret";'
      CONNECT_CONSUMER_SASL_MECHANISM: PLAIN

      #CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: 'ALL'

    volumes:
      - ./plugins/kafka-plugins:/kafka-plugins
      - ./metrics/sample-flat-schema-metric/config:/sample-flat-schema-metric-config
      - ./scripts:/scripts
      - ./metrics/sample-nested-schema-metric/config:/sample-nested-schema-metric-config
      - ./mongodb-kafka-connect-mongodb-1.14.1:/usr/share/confluent-hub-components
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/"]
      interval: 30s
      timeout: 10s
      retries: 5

# connector.client.config.override.policy
# kafka-acls --bootstrap-server localhost:9092 --command-config adminclient-configs.conf \
#  --add --allow-principal User:<Sink Connector Principal> \
#  --consumer --topic logs --group connect-hdfs-logs


  control-center-2:
    image: confluentinc/cp-enterprise-control-center:7.6.0
    container_name: control-center-2
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka-2:29094'
      CONTROL_CENTER_CONNECT_CONNECT_CLUSTER: 'kafka-connect-2:8083'
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8085'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONTROL_CENTER_CONNECT_HEALTHCHECK_ENDPOINT: '/connectors'
      CONTROL_CENTER_LOG4J_ROOT_LOGLEVEL: 'INFO'
    depends_on:
      - kafka-2

volumes:
  kafka-data:
  kafka-data-2:
  connect-plugins:
  mongo-data:
